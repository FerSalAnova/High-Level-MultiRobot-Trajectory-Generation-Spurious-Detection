{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064e85ab-328c-4a76-a9a4-b696cd346e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\salan\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\salan\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\salan\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\salan\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\salan\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1bc0af-bee2-4def-a540-13108b0300a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b378341-a5ba-4fae-bc86-4efa87c403dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################    EMBED DATA   ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb1eecd-1c5a-47c2-acbb-c0a83fd7baab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'robot_id': 1, 'duration': 8, 'p_start': 2, 'y_start': [1, 7], 'p_end': 14, 'y_end': [4]}, {'robot_id': 4, 'duration': 10, 'p_start': 2, 'y_start': [1], 'p_end': 1, 'y_end': [2]}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import re\n",
    "\n",
    "def parse_trajectories(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    blocks = content.strip().split(\"\\n\\n\")  # Split by blocks separated by blank lines\n",
    "    all_trajectories = []\n",
    "\n",
    "    for block in blocks:\n",
    "        lines = block.strip().split(\"\\n\")\n",
    "        trajectory = []\n",
    "\n",
    "        for line in lines:\n",
    "            actions = line.strip().split(\"-\")  # Each action is separated by '-'\n",
    "            timestep = []\n",
    "\n",
    "            for action in actions:\n",
    "                # Adjust the regex to capture multiple labels in the format pX(y1,y2,...)\n",
    "                match = re.match(r\"r(\\d+)\\((\\d+)\\):p(\\d+)\\(([^)]+)\\),p(\\d+)\\(([^)]+)\\)\", action.strip())\n",
    "                if match:\n",
    "                    r_id, duration, p_start, y_start_str, p_end, y_end_str = match.groups()\n",
    "                    \n",
    "                    # Extract numeric label values (e.g., 'y1', 'y7' â†’ 1, 7)\n",
    "                    y_start = [int(label[1:]) for label in y_start_str.split(',')]\n",
    "                    y_end = [int(label[1:]) for label in y_end_str.split(',')]\n",
    "\n",
    "                    timestep.append({\n",
    "                        \"robot_id\": int(r_id),\n",
    "                        \"duration\": int(duration),\n",
    "                        \"p_start\": int(p_start),\n",
    "                        \"y_start\": y_start,\n",
    "                        \"p_end\": int(p_end),\n",
    "                        \"y_end\": y_end\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Warning: Could not parse action: {action}\")\n",
    "            trajectory.append(timestep)\n",
    "\n",
    "        all_trajectories.append(trajectory)\n",
    "\n",
    "    return all_trajectories\n",
    "\n",
    "# Parse the data from the log file\n",
    "parsed_data = parse_trajectories(\"log.txt\")\n",
    "\n",
    "# Print the parsed data for the first timestep in the first trajectory\n",
    "print(parsed_data[0][0])  # first timestep in that trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687e0302-8f60-40e9-b82a-322223a6b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Compute max ids from the parsed data\n",
    "robot_ids = set()\n",
    "place_ids = set()\n",
    "\n",
    "for traj in parsed_data:\n",
    "    for timestep in traj:\n",
    "        for action in timestep:\n",
    "            robot_ids.add(action['robot_id'])\n",
    "            place_ids.add(action['p_start'])\n",
    "            place_ids.add(action['p_end'])\n",
    "\n",
    "max_robot_id = max(robot_ids) + 1\n",
    "max_place_id = max(place_ids) + 1\n",
    "max_timesteps = max(len(traj) for traj in parsed_data)\n",
    "\n",
    "# Then initialize your embeddings\n",
    "embed_dim = 32\n",
    "robot_embedding_matrix = nn.Embedding(max_robot_id, embed_dim)\n",
    "place_embedding_matrix = nn.Embedding(max_place_id, embed_dim)\n",
    "timestep_embedding_matrix = nn.Embedding(max_timesteps, embed_dim)\n",
    "\n",
    "# If you want to just use tensors here, extract their weight data:\n",
    "robot_embeddings = robot_embedding_matrix.weight.data  # shape (max_robot_id, embed_dim)\n",
    "place_embeddings = place_embedding_matrix.weight.data  # shape (max_place_id, embed_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b241719-c9f7-46bf-a176-c2faf3b8da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(value, dim=32):\n",
    "    \"\"\"Sinusoidal embedding for a scalar value.\"\"\"\n",
    "    pe = torch.zeros(dim)\n",
    "    position = torch.tensor(value, dtype=torch.float32)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(np.log(10000.0) / dim))\n",
    "    pe[0::2] = torch.sin(position * div_term)\n",
    "    pe[1::2] = torch.cos(position * div_term)\n",
    "    return pe\n",
    "\n",
    "def time_embedding(duration, max_duration):\n",
    "    \"\"\"Sinusoidal encoding for duration using 2D angle.\"\"\"\n",
    "    normalized = np.log(duration + 1) / np.log(max_duration + 1)\n",
    "    angle = 2 * np.pi * normalized\n",
    "    return torch.tensor([np.sin(angle), np.cos(angle)], dtype=torch.float32)\n",
    "\n",
    "def label_embedding(y_start, y_end, num_labels=5):\n",
    "    \"\"\"Label transition encoding: -1 for origin labels, 1 for destination labels, 0 otherwise.\"\"\"\n",
    "    vec = torch.zeros(num_labels)\n",
    "    for i in y_start:\n",
    "        vec[i - 1] = -1\n",
    "    for i in y_end:\n",
    "        if vec[i - 1] == -1:\n",
    "            vec[i - 1] = 0  # neutralize if label is both in start and end\n",
    "        else:\n",
    "            vec[i - 1] = 1\n",
    "    return vec\n",
    "\n",
    "def timestep_embedding(position, dim=32):\n",
    "    \"\"\"Sinusoidal positional encoding for timestep index.\"\"\"\n",
    "    pe = torch.zeros(dim)\n",
    "    position = torch.tensor(position, dtype=torch.float32)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(np.log(10000.0) / dim))\n",
    "    pe[0::2] = torch.sin(position * div_term)\n",
    "    pe[1::2] = torch.cos(position * div_term)\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a596bd-f806-4871-b8f2-2210cc730fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_actions(parsed_data, robot_embeddings, place_embeddings, timestep_embeddings, num_labels=5, embed_dim=32):\n",
    "    max_duration = max(\n",
    "        action['duration']\n",
    "        for trajectory in parsed_data\n",
    "        for timestep in trajectory\n",
    "        for action in timestep\n",
    "    )\n",
    "    \n",
    "    encoded_vectors = []\n",
    "\n",
    "    for trajectory in parsed_data:\n",
    "        encoded_trajectory = []\n",
    "\n",
    "        for t_idx, timestep in enumerate(trajectory):\n",
    "            timestep_vec = timestep_embeddings[t_idx]\n",
    "\n",
    "            encoded_timestep = []\n",
    "\n",
    "            for action in timestep:\n",
    "                # Instead of sinusoidal, do lookup here:\n",
    "                robot_vec = robot_embeddings[action['robot_id']]  \n",
    "                p_start_vec = place_embeddings[action['p_start']]\n",
    "                p_end_vec = place_embeddings[action['p_end']]\n",
    "\n",
    "                label_vec = label_embedding(action['y_start'], action['y_end'], num_labels=num_labels)\n",
    "                time_vec = time_embedding(action['duration'], 10)\n",
    "\n",
    "                full_vec = torch.cat([\n",
    "                    robot_vec,\n",
    "                    p_start_vec,\n",
    "                    p_end_vec,\n",
    "                    label_vec,\n",
    "                    time_vec,\n",
    "                    timestep_vec\n",
    "                ])\n",
    "\n",
    "                encoded_timestep.append(full_vec)\n",
    "            encoded_trajectory.append(encoded_timestep)\n",
    "\n",
    "        encoded_vectors.append(encoded_trajectory)\n",
    "\n",
    "    return encoded_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb96dd5-862f-42eb-9d11-3ecee833206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data from the log file\n",
    "parsed_data = parse_trajectories(\"Datasets/Dataset1/DataSet_Balanced.txt\")\n",
    "\n",
    "# Set the number of labels manually\n",
    "num_labels = 7  # Change this based on the number of labels you want\n",
    "\n",
    "# Example: create embedding matrices (trainable parameters should be managed separately during training)\n",
    "robot_embedding_matrix = nn.Embedding(max_robot_id, embed_dim)\n",
    "place_embedding_matrix = nn.Embedding(max_place_id, embed_dim)\n",
    "\n",
    "# Pass the weight tensors:\n",
    "encoded_vectors = encode_actions(\n",
    "    parsed_data,\n",
    "    robot_embedding_matrix.weight.data,\n",
    "    place_embedding_matrix.weight.data,\n",
    "    timestep_embeddings=timestep_embedding_matrix.weight.data,\n",
    "    num_labels=num_labels,\n",
    "    embed_dim=embed_dim\n",
    ")\n",
    "\n",
    "# Print the encoded vector for the first timestep in the first trajectory\n",
    "print(encoded_vectors[0][0][0])  # First timestep in the first trajectory\n",
    "print(f\"Vector size: {encoded_vectors[0][0][0].shape}\")  # Expected size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d0087cb-2d4d-4db6-b085-c7c468dd0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################   PREPARE DATA    #######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08f7ac4e-5153-43d9-880f-f1437db9a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pad_trajectories(encoded_vectors):\n",
    "    max_timesteps = max(len(traj) for traj in encoded_vectors)\n",
    "    max_actions = max(len(ts) for traj in encoded_vectors for ts in traj)\n",
    "    feature_dim = encoded_vectors[0][0][0].shape[-1]\n",
    "\n",
    "    padded_trajectories = []\n",
    "    action_masks = []\n",
    "    timestep_masks = []\n",
    "\n",
    "    for traj in encoded_vectors:\n",
    "        padded_traj = []\n",
    "        traj_action_mask = []\n",
    "        for ts in traj:\n",
    "            # Pad actions within this timestep\n",
    "            real_actions = len(ts)\n",
    "            padded_ts = ts + [torch.zeros(feature_dim)] * (max_actions - real_actions)\n",
    "            padded_ts_tensor = torch.stack(padded_ts)  # (A, D)\n",
    "            padded_traj.append(padded_ts_tensor)\n",
    "\n",
    "            # Action mask: 1 for real actions, 0 for padded\n",
    "            action_mask = [1] * real_actions + [0] * (max_actions - real_actions)\n",
    "            traj_action_mask.append(torch.tensor(action_mask, dtype=torch.bool))  # (A,)\n",
    "\n",
    "        # Pad timesteps\n",
    "        num_real_timesteps = len(traj)\n",
    "        empty_ts = torch.zeros(max_actions, feature_dim)\n",
    "        padded_traj += [empty_ts] * (max_timesteps - num_real_timesteps)\n",
    "        padded_traj_tensor = torch.stack(padded_traj)  # (T, A, D)\n",
    "        padded_trajectories.append(padded_traj_tensor)\n",
    "\n",
    "        # Pad action mask\n",
    "        empty_action_mask = torch.zeros(max_actions, dtype=torch.bool)\n",
    "        traj_action_mask += [empty_action_mask] * (max_timesteps - num_real_timesteps)\n",
    "        action_masks.append(torch.stack(traj_action_mask))  # (T, A)\n",
    "\n",
    "        # Timestep mask: 1 for real timesteps, 0 for padded\n",
    "        timestep_mask = [1] * num_real_timesteps + [0] * (max_timesteps - num_real_timesteps)\n",
    "        timestep_masks.append(torch.tensor(timestep_mask, dtype=torch.bool))  # (T,)\n",
    "\n",
    "    return (\n",
    "        torch.stack(padded_trajectories),  # (B, T, A, D)\n",
    "        torch.stack(action_masks),         # (B, T, A)\n",
    "        torch.stack(timestep_masks),       # (B, T)\n",
    "    )\n",
    "\n",
    "\n",
    "data_tensor, action_mask, timestep_mask = pad_trajectories(encoded_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7afa1b-b707-477b-b9cd-9389cded0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Tensor Shape: torch.Size([5200, 39, 4, 137])\n",
      "Action Mask Shape: torch.Size([5200, 39, 4])\n",
      "Timestep Mask Shape: torch.Size([5200, 39])\n",
      "\n",
      "Trajectory 0:\n",
      "Timestep lengths: [1, 4, 2, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Timestep mask: [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Trajectory 0, Timestep 2 â€” Action Mask: [1, 1, 0, 0]\n",
      "Data tensor (values) shape: torch.Size([4, 137])\n",
      "First action vector (real or zero): tensor([ 0.9777, -0.7392, -0.4093, -0.2958,  0.9308, -0.8573, -0.0022, -0.5086,\n",
      "        -0.3886, -0.4624, -1.5779,  0.2407, -0.4397, -0.6403, -1.3094,  0.9380,\n",
      "        -1.1098,  0.8411,  0.0365, -1.6489,  0.5481,  0.8254, -0.8321, -0.8304,\n",
      "        -0.2717, -0.0426, -0.1333, -1.7681, -0.8077,  1.2070,  0.4288,  1.7007,\n",
      "        -0.8839, -0.7609,  1.3325,  0.3432,  1.2239, -0.4532,  1.0612,  0.6864,\n",
      "        -1.3334, -0.6102,  0.3203, -0.9472, -0.2373,  0.7677, -1.8694, -0.6299,\n",
      "        -1.0208,  0.5670,  0.2484,  0.5270, -1.3465, -0.5851,  0.2687,  1.0101,\n",
      "         1.9395,  0.0536, -1.4538,  0.1131, -0.7059,  0.0554, -0.1905, -0.3961,\n",
      "        -0.7712,  1.3902,  1.3212, -1.1596, -0.1486, -1.7308, -1.4923,  0.3367,\n",
      "         1.6509,  0.0473, -0.0481, -0.8983, -1.5069,  1.0064, -0.5449, -0.1714,\n",
      "        -0.6794,  0.8585, -1.2348, -0.1810, -0.6104,  0.3877, -0.2895,  0.0454,\n",
      "         1.0438,  0.3568, -0.4086,  0.9569,  1.0708, -0.9102,  1.1328,  0.5881,\n",
      "         1.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0000,  0.0000, -0.9998,\n",
      "        -0.0175, -0.9571,  0.2166, -0.4581,  0.1415,  0.6014,  0.8913, -0.3624,\n",
      "        -0.7932, -0.2313,  1.1898,  1.2164,  0.8857, -2.1665,  1.8260, -0.1628,\n",
      "         1.2036,  0.0956, -0.5797,  0.0402, -0.0587,  0.4966,  1.2487, -0.0285,\n",
      "         1.3137,  0.3170, -0.5143, -0.6256, -0.1225,  0.6912,  0.0656, -0.5021,\n",
      "         0.8280])\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Tensor Shape:\", data_tensor.shape)          # (B, T, A, D)\n",
    "print(\"Action Mask Shape:\", action_mask.shape)          # (B, T, A)\n",
    "print(\"Timestep Mask Shape:\", timestep_mask.shape)      # (B, T)\n",
    "\n",
    "# --- Check a specific trajectory ---\n",
    "i = 0  # Check the first trajectory\n",
    "\n",
    "print(f\"\\nTrajectory {i}:\")\n",
    "print(\"Timestep lengths:\", [sum(am).item() for am in action_mask[i]])  # Number of real actions per timestep\n",
    "print(\"Timestep mask:\", timestep_mask[i].int().tolist())               # 1 if real timestep, 0 if padded\n",
    "\n",
    "# --- Visual check for one timestep ---\n",
    "t = 2  # First timestep\n",
    "print(f\"\\nTrajectory {i}, Timestep {t} â€” Action Mask:\", action_mask[i][t].int().tolist())\n",
    "print(f\"Data tensor (values) shape: {data_tensor[i][t].shape}\")\n",
    "print(\"First action vector (real or zero):\", data_tensor[i][t][0])  # Show first 5 dims of first action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "813940bb-2719-4ef4-b99f-b6ae57aa94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.data import TensorDataset, Subset\n",
    "\n",
    "# Create full dataset\n",
    "dataset = TensorDataset(data_tensor, action_mask, timestep_mask)\n",
    "\n",
    "normal_indices = list(range(0, 1000)) + list(range(1100, 5100))   # 5000 normal\n",
    "abnormal_indices = list(range(1000, 1100)) + list(range(5100, 5200))  # 200 abnormal\n",
    "\n",
    "# Split normal indices into 80/10/10\n",
    "train_len = int(0.8 * len(normal_indices))\n",
    "val_len = int(0.1 * len(normal_indices))\n",
    "test_normal_len = len(normal_indices) - train_len - val_len\n",
    "\n",
    "# Shuffle deterministically\n",
    "g = torch.Generator().manual_seed(30)\n",
    "permuted = torch.randperm(len(normal_indices), generator=g).tolist()\n",
    "\n",
    "train_indices = [normal_indices[i] for i in permuted[:train_len]]\n",
    "val_indices   = [normal_indices[i] for i in permuted[train_len:train_len + val_len]]\n",
    "test_indices  = [normal_indices[i] for i in permuted[train_len + val_len:]]\n",
    "\n",
    "# Add abnormal indices to test set\n",
    "test_indices += abnormal_indices\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset   = Subset(dataset, val_indices)\n",
    "test_dataset  = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f6d1dc3-ab49-4871-a53c-6795fb9c1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 250\n",
      "Validation batches: 32\n",
      "Test batches: 44\n",
      "Data batch shape: torch.Size([16, 39, 4, 137])\n",
      "Action mask shape: torch.Size([16, 39, 4])\n",
      "Timestep mask shape: torch.Size([16, 39])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Validation batches:\", len(val_loader))\n",
    "print(\"Test batches:\", len(test_loader))\n",
    "\n",
    "# Check one batch\n",
    "for data_batch, action_mask_batch, timestep_mask_batch in train_loader:\n",
    "    print(\"Data batch shape:\", data_batch.shape)  # (B, T, A, D)\n",
    "    print(\"Action mask shape:\", action_mask_batch.shape)  # (B, T, A)\n",
    "    print(\"Timestep mask shape:\", timestep_mask_batch.shape)  # (B, T)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "022a42e4-8e34-4294-8b22-50cf3d071b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################    MODEL ARCHITECTURE    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98cecb0c-f5c8-4772-9b3e-e9f3c00a2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ActionTransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # x: (B*T, A, embed_dim)\n",
    "        # mask: (B*T, A) bool mask, True=valid\n",
    "        key_padding_mask = ~mask  # Transformer expects True for padding tokens\n",
    "        out = self.transformer_encoder(x, src_key_padding_mask=key_padding_mask)\n",
    "        return out  # (B*T, A, embed_dim)\n",
    "\n",
    "class TrajectoryAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=64, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        self.action_encoder = ActionTransformerEncoder(\n",
    "            input_dim=input_dim,\n",
    "            embed_dim=embed_dim,\n",
    "            nhead=nhead,\n",
    "            num_layers=num_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        timestep_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.timestep_encoder = nn.TransformerEncoder(\n",
    "            timestep_encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Decoder projects from embed_dim back to original feature dim (D)\n",
    "        self.decoder = nn.Linear(embed_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x, action_mask, timestep_mask):\n",
    "        # x: (B, T, A, D)\n",
    "        B, T, A, D = x.shape\n",
    "        \n",
    "        # Flatten timesteps to batch dim for action encoder\n",
    "        x_flat = x.view(B * T, A, D)  # (B*T, A, D)\n",
    "        action_mask_flat = action_mask.view(B * T, A)  # (B*T, A)\n",
    "        \n",
    "        # Input projection\n",
    "        x_proj = self.input_proj(x_flat)  # (B*T, A, embed_dim)\n",
    "        \n",
    "        # Encode actions\n",
    "        action_encoded = self.action_encoder(x_proj, action_mask_flat)  # (B*T, A, embed_dim)\n",
    "        \n",
    "        # Reshape back to (B, T, A, embed_dim)\n",
    "        action_encoded = action_encoded.view(B, T, A, -1)\n",
    "        \n",
    "        # Aggregate per timestep: mean over valid actions (mask-aware mean)\n",
    "        # Masked mean: sum / count\n",
    "        masked_sum = (action_encoded * action_mask.unsqueeze(-1)).sum(dim=2)  # (B, T, embed_dim)\n",
    "        valid_counts = action_mask.sum(dim=2).clamp(min=1).unsqueeze(-1)  # avoid div by 0\n",
    "        timestep_repr = masked_sum / valid_counts  # (B, T, embed_dim)\n",
    "        \n",
    "        # Encode timesteps\n",
    "        # Transformer expects key_padding_mask True for padded\n",
    "        key_padding_mask = ~timestep_mask  # (B, T)\n",
    "        timestep_encoded = self.timestep_encoder(timestep_repr, src_key_padding_mask=key_padding_mask)  # (B, T, embed_dim)\n",
    "        \n",
    "        # Decode per action: replicate timestep_encoded per action\n",
    "        timestep_expanded = timestep_encoded.unsqueeze(2).repeat(1, 1, A, 1)  # (B, T, A, embed_dim)\n",
    "        \n",
    "        out = self.decoder(timestep_expanded)  # (B, T, A, D)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81e9a7d4-efb0-4ce0-8fd7-d8bdbe97ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################    TRAIN    #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6635ef4d-7377-4b96-976d-70a94bb0762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 â€” Train Loss: 57.1254 â€” Val Loss: 42.9894\n",
      "Epoch 2/30 â€” Train Loss: 42.6846 â€” Val Loss: 41.7647\n",
      "Epoch 3/30 â€” Train Loss: 41.8787 â€” Val Loss: 41.5219\n",
      "Epoch 4/30 â€” Train Loss: 41.6754 â€” Val Loss: 41.4052\n",
      "Epoch 5/30 â€” Train Loss: 41.5510 â€” Val Loss: 41.3487\n",
      "Epoch 6/30 â€” Train Loss: 41.4630 â€” Val Loss: 41.3222\n",
      "Epoch 7/30 â€” Train Loss: 41.4330 â€” Val Loss: 41.2905\n",
      "Epoch 8/30 â€” Train Loss: 41.4094 â€” Val Loss: 41.2826\n",
      "Epoch 9/30 â€” Train Loss: 41.4152 â€” Val Loss: 41.2708\n",
      "Epoch 10/30 â€” Train Loss: 41.4059 â€” Val Loss: 41.2637\n",
      "Epoch 11/30 â€” Train Loss: 41.3806 â€” Val Loss: 41.2621\n",
      "Epoch 12/30 â€” Train Loss: 41.3672 â€” Val Loss: 41.2556\n",
      "Epoch 13/30 â€” Train Loss: 41.3659 â€” Val Loss: 41.2557\n",
      "Epoch 14/30 â€” Train Loss: 41.3594 â€” Val Loss: 41.2527\n",
      "Epoch 15/30 â€” Train Loss: 41.3813 â€” Val Loss: 41.2498\n",
      "Epoch 16/30 â€” Train Loss: 41.3583 â€” Val Loss: 41.2491\n",
      "Epoch 17/30 â€” Train Loss: 41.3727 â€” Val Loss: 41.2509\n",
      "Epoch 18/30 â€” Train Loss: 41.3581 â€” Val Loss: 41.2517\n",
      "Epoch 19/30 â€” Train Loss: 41.3420 â€” Val Loss: 41.2476\n",
      "Epoch 20/30 â€” Train Loss: 41.3380 â€” Val Loss: 41.2459\n",
      "Epoch 21/30 â€” Train Loss: 41.3466 â€” Val Loss: 41.2728\n",
      "Epoch 22/30 â€” Train Loss: 41.3552 â€” Val Loss: 41.2438\n",
      "Epoch 23/30 â€” Train Loss: 41.3637 â€” Val Loss: 41.2478\n",
      "Epoch 24/30 â€” Train Loss: 41.3287 â€” Val Loss: 41.2444\n",
      "Epoch 25/30 â€” Train Loss: 41.3484 â€” Val Loss: 41.2437\n",
      "Epoch 26/30 â€” Train Loss: 41.3514 â€” Val Loss: 41.2446\n",
      "Epoch 27/30 â€” Train Loss: 41.3484 â€” Val Loss: 41.2424\n",
      "Epoch 28/30 â€” Train Loss: 41.3550 â€” Val Loss: 41.2432\n",
      "Epoch 29/30 â€” Train Loss: 41.3425 â€” Val Loss: 41.2427\n",
      "Epoch 30/30 â€” Train Loss: 41.3563 â€” Val Loss: 41.2406\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def masked_mse_loss(pred, target, mask):\n",
    "    # pred, target: (B, T, A, D)\n",
    "    # mask: (B, T, A) bool, True=valid data points\n",
    "    mask = mask.unsqueeze(-1)  # (B, T, A, 1)\n",
    "    diff = (pred - target) ** 2\n",
    "    diff = diff * mask  # zero out padded\n",
    "    return diff.sum() / mask.sum().clamp(min=1)  # mean over valid elements\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, device, epochs=20):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, action_mask, timestep_mask in train_loader:\n",
    "            x = x.to(device)\n",
    "            action_mask = action_mask.to(device)\n",
    "            timestep_mask = timestep_mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x, action_mask, timestep_mask)\n",
    "\n",
    "            # Combine masks for valid actions inside valid timesteps\n",
    "            combined_mask = action_mask & timestep_mask.unsqueeze(-1)\n",
    "\n",
    "            loss = masked_mse_loss(out, x, combined_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, action_mask, timestep_mask in val_loader:\n",
    "                x = x.to(device)\n",
    "                action_mask = action_mask.to(device)\n",
    "                timestep_mask = timestep_mask.to(device)\n",
    "\n",
    "                out = model(x, action_mask, timestep_mask)\n",
    "                combined_mask = action_mask & timestep_mask.unsqueeze(-1)\n",
    "                loss = masked_mse_loss(out, x, combined_mask)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} â€” Train Loss: {train_loss:.4f} â€” Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_trajectory_autoencoder.pth\")\n",
    "\n",
    "# Example usage:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TrajectoryAutoencoder(input_dim=data_tensor.shape[-1], embed_dim=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(model, train_loader, val_loader, optimizer, device, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "001f839c-1245-4032-b46d-d8367364eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################    VISUALIZE RESULTS    #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c63df3c9-f898-4ba6-944e-e239a1b7b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_anomalies(model, test_loader, device, test_indices, top_k=5):\n",
    "    \"\"\"\n",
    "    Evaluates anomalies by computing reconstruction loss for each trajectory and\n",
    "    associating it with the original dataset index using `test_indices`.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test set.\n",
    "        device (torch.device): Device to run inference on.\n",
    "        test_indices (list of int): Original indices corresponding to test_loader data.\n",
    "        top_k (int): Number of top anomalies to display.\n",
    "\n",
    "    Returns:\n",
    "        sorted_pairs (list of tuples): List of (original_index, loss), sorted by loss descending.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start = 0  # Pointer in test_indices\n",
    "        for x, action_mask, timestep_mask in test_loader:\n",
    "            x = x.to(device)\n",
    "            action_mask = action_mask.to(device)\n",
    "            timestep_mask = timestep_mask.to(device)\n",
    "\n",
    "            out = model(x, action_mask, timestep_mask)\n",
    "\n",
    "            # Calculate per-sample loss\n",
    "            mask = action_mask & timestep_mask.unsqueeze(-1)\n",
    "            diff = (out - x) ** 2 * mask.unsqueeze(-1)\n",
    "            loss_per_sample = diff.sum(dim=[1, 2, 3]) / mask.sum(dim=[1, 2]).clamp(min=1)\n",
    "\n",
    "            # Map to original IDs\n",
    "            batch_size = x.size(0)\n",
    "            batch_ids = test_indices[start:start + batch_size]\n",
    "            start += batch_size\n",
    "\n",
    "            losses.extend(loss_per_sample.cpu().tolist())\n",
    "            ids.extend(batch_ids)\n",
    "\n",
    "    # Pair (original ID, loss) and sort\n",
    "    sorted_pairs = sorted(zip(ids, losses), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f\"Top {top_k} most abnormal trajectories (ID and reconstruction loss):\")\n",
    "    for traj_id, loss in sorted_pairs[:top_k]:\n",
    "        print(f\"Trajectory ID {traj_id}: Loss = {loss:.4f}\")\n",
    "\n",
    "    return sorted_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36a52c03-38d8-4dfe-9bd5-8eed90a56a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 500 most abnormal trajectories (ID and reconstruction loss):\n",
      "Trajectory ID 1022: Loss = 61.1130\n",
      "Trajectory ID 1017: Loss = 60.2809\n",
      "Trajectory ID 1056: Loss = 59.8945\n",
      "Trajectory ID 5108: Loss = 59.4831\n",
      "Trajectory ID 5103: Loss = 59.4693\n",
      "Trajectory ID 5142: Loss = 59.3265\n",
      "Trajectory ID 1058: Loss = 58.8943\n",
      "Trajectory ID 1093: Loss = 58.7785\n",
      "Trajectory ID 1010: Loss = 58.2182\n",
      "Trajectory ID 5133: Loss = 58.0130\n",
      "Trajectory ID 1062: Loss = 58.0024\n",
      "Trajectory ID 5179: Loss = 57.9569\n",
      "Trajectory ID 1019: Loss = 57.7927\n",
      "Trajectory ID 1031: Loss = 57.7583\n",
      "Trajectory ID 1081: Loss = 57.6966\n",
      "Trajectory ID 1024: Loss = 57.3848\n",
      "Trajectory ID 1097: Loss = 57.3369\n",
      "Trajectory ID 5181: Loss = 56.7913\n",
      "Trajectory ID 1046: Loss = 56.6227\n",
      "Trajectory ID 5127: Loss = 56.3987\n",
      "Trajectory ID 1086: Loss = 56.3360\n",
      "Trajectory ID 1014: Loss = 56.3124\n",
      "Trajectory ID 1088: Loss = 56.3079\n",
      "Trajectory ID 1011: Loss = 56.2068\n",
      "Trajectory ID 5197: Loss = 56.1398\n",
      "Trajectory ID 1006: Loss = 56.1246\n",
      "Trajectory ID 2716: Loss = 56.0435\n",
      "Trajectory ID 1063: Loss = 56.0196\n",
      "Trajectory ID 5136: Loss = 56.0154\n",
      "Trajectory ID 1026: Loss = 55.9945\n",
      "Trajectory ID 5192: Loss = 55.9939\n",
      "Trajectory ID 1068: Loss = 55.9246\n",
      "Trajectory ID 1076: Loss = 55.8296\n",
      "Trajectory ID 5156: Loss = 55.7988\n",
      "Trajectory ID 1099: Loss = 55.5948\n",
      "Trajectory ID 5155: Loss = 55.4883\n",
      "Trajectory ID 2400: Loss = 55.4282\n",
      "Trajectory ID 1008: Loss = 55.3810\n",
      "Trajectory ID 5175: Loss = 55.3384\n",
      "Trajectory ID 1005: Loss = 55.3074\n",
      "Trajectory ID 5152: Loss = 55.1864\n",
      "Trajectory ID 1038: Loss = 55.1029\n",
      "Trajectory ID 1087: Loss = 55.0222\n",
      "Trajectory ID 1082: Loss = 54.9966\n",
      "Trajectory ID 5153: Loss = 54.9637\n",
      "Trajectory ID 3322: Loss = 54.9629\n",
      "Trajectory ID 5120: Loss = 54.9102\n",
      "Trajectory ID 1052: Loss = 54.7318\n",
      "Trajectory ID 2799: Loss = 54.6633\n",
      "Trajectory ID 5123: Loss = 54.6622\n",
      "Trajectory ID 5161: Loss = 54.6397\n",
      "Trajectory ID 3995: Loss = 54.6080\n",
      "Trajectory ID 5100: Loss = 54.4113\n",
      "Trajectory ID 5137: Loss = 54.3754\n",
      "Trajectory ID 1091: Loss = 54.2969\n",
      "Trajectory ID 5126: Loss = 54.1450\n",
      "Trajectory ID 5149: Loss = 54.0288\n",
      "Trajectory ID 1078: Loss = 54.0222\n",
      "Trajectory ID 5150: Loss = 53.9031\n",
      "Trajectory ID 5183: Loss = 53.8082\n",
      "Trajectory ID 5182: Loss = 53.7948\n",
      "Trajectory ID 1070: Loss = 53.5886\n",
      "Trajectory ID 5194: Loss = 53.5812\n",
      "Trajectory ID 5118: Loss = 53.5191\n",
      "Trajectory ID 1020: Loss = 53.3693\n",
      "Trajectory ID 5189: Loss = 53.3622\n",
      "Trajectory ID 5115: Loss = 53.2750\n",
      "Trajectory ID 5158: Loss = 53.2385\n",
      "Trajectory ID 5186: Loss = 53.1046\n",
      "Trajectory ID 1016: Loss = 53.0776\n",
      "Trajectory ID 5147: Loss = 53.0372\n",
      "Trajectory ID 5178: Loss = 52.7247\n",
      "Trajectory ID 5196: Loss = 52.6036\n",
      "Trajectory ID 5198: Loss = 52.3994\n",
      "Trajectory ID 634: Loss = 52.3365\n",
      "Trajectory ID 1041: Loss = 52.2874\n",
      "Trajectory ID 1069: Loss = 52.2686\n",
      "Trajectory ID 5130: Loss = 52.2386\n",
      "Trajectory ID 5107: Loss = 52.1228\n",
      "Trajectory ID 5112: Loss = 52.1123\n",
      "Trajectory ID 213: Loss = 52.0956\n",
      "Trajectory ID 247: Loss = 51.9824\n",
      "Trajectory ID 2581: Loss = 51.8417\n",
      "Trajectory ID 5113: Loss = 51.8329\n",
      "Trajectory ID 1072: Loss = 51.8002\n",
      "Trajectory ID 1030: Loss = 51.7164\n",
      "Trajectory ID 5140: Loss = 51.6204\n",
      "Trajectory ID 1074: Loss = 51.5867\n",
      "Trajectory ID 166: Loss = 51.5831\n",
      "Trajectory ID 512: Loss = 51.5361\n",
      "Trajectory ID 1043: Loss = 51.4596\n",
      "Trajectory ID 1009: Loss = 51.3724\n",
      "Trajectory ID 2518: Loss = 51.3193\n",
      "Trajectory ID 4075: Loss = 51.2832\n",
      "Trajectory ID 2020: Loss = 51.2661\n",
      "Trajectory ID 5145: Loss = 51.1744\n",
      "Trajectory ID 3115: Loss = 51.1383\n",
      "Trajectory ID 1018: Loss = 51.1222\n",
      "Trajectory ID 1059: Loss = 51.0433\n",
      "Trajectory ID 470: Loss = 51.0090\n",
      "Trajectory ID 1001: Loss = 50.9839\n",
      "Trajectory ID 1083: Loss = 50.9838\n",
      "Trajectory ID 3239: Loss = 50.9708\n",
      "Trajectory ID 5199: Loss = 50.9549\n",
      "Trajectory ID 3650: Loss = 50.8750\n",
      "Trajectory ID 1095: Loss = 50.8641\n",
      "Trajectory ID 1532: Loss = 50.7537\n",
      "Trajectory ID 786: Loss = 50.7172\n",
      "Trajectory ID 5072: Loss = 50.6998\n",
      "Trajectory ID 1080: Loss = 50.6887\n",
      "Trajectory ID 1035: Loss = 50.6187\n",
      "Trajectory ID 1049: Loss = 50.6148\n",
      "Trajectory ID 1027: Loss = 50.5707\n",
      "Trajectory ID 4876: Loss = 50.5076\n",
      "Trajectory ID 1077: Loss = 50.4334\n",
      "Trajectory ID 5135: Loss = 50.3528\n",
      "Trajectory ID 2721: Loss = 50.3501\n",
      "Trajectory ID 2838: Loss = 50.3477\n",
      "Trajectory ID 2503: Loss = 50.3466\n",
      "Trajectory ID 3529: Loss = 50.3099\n",
      "Trajectory ID 4985: Loss = 50.3072\n",
      "Trajectory ID 5171: Loss = 50.3054\n",
      "Trajectory ID 1042: Loss = 50.2679\n",
      "Trajectory ID 3458: Loss = 50.2211\n",
      "Trajectory ID 1012: Loss = 50.2186\n",
      "Trajectory ID 1079: Loss = 50.2131\n",
      "Trajectory ID 1096: Loss = 50.1796\n",
      "Trajectory ID 5125: Loss = 50.1078\n",
      "Trajectory ID 3515: Loss = 50.1033\n",
      "Trajectory ID 5188: Loss = 50.0259\n",
      "Trajectory ID 5141: Loss = 49.9858\n",
      "Trajectory ID 1007: Loss = 49.9663\n",
      "Trajectory ID 5159: Loss = 49.9608\n",
      "Trajectory ID 1073: Loss = 49.9103\n",
      "Trajectory ID 980: Loss = 49.8704\n",
      "Trajectory ID 1245: Loss = 49.7778\n",
      "Trajectory ID 5131: Loss = 49.7582\n",
      "Trajectory ID 1067: Loss = 49.7316\n",
      "Trajectory ID 1075: Loss = 49.6997\n",
      "Trajectory ID 1047: Loss = 49.6856\n",
      "Trajectory ID 5138: Loss = 49.6807\n",
      "Trajectory ID 5157: Loss = 49.6689\n",
      "Trajectory ID 5191: Loss = 49.5910\n",
      "Trajectory ID 1028: Loss = 49.5397\n",
      "Trajectory ID 1640: Loss = 49.4854\n",
      "Trajectory ID 1718: Loss = 49.3989\n",
      "Trajectory ID 1055: Loss = 49.3980\n",
      "Trajectory ID 2062: Loss = 49.3879\n",
      "Trajectory ID 2837: Loss = 49.2402\n",
      "Trajectory ID 5170: Loss = 49.1667\n",
      "Trajectory ID 4296: Loss = 49.1454\n",
      "Trajectory ID 238: Loss = 49.1321\n",
      "Trajectory ID 1094: Loss = 49.1102\n",
      "Trajectory ID 1092: Loss = 49.0909\n",
      "Trajectory ID 3315: Loss = 49.0015\n",
      "Trajectory ID 1033: Loss = 48.9959\n",
      "Trajectory ID 5168: Loss = 48.9749\n",
      "Trajectory ID 1003: Loss = 48.9303\n",
      "Trajectory ID 1090: Loss = 48.9081\n",
      "Trajectory ID 2036: Loss = 48.8935\n",
      "Trajectory ID 3423: Loss = 48.8880\n",
      "Trajectory ID 4537: Loss = 48.8492\n",
      "Trajectory ID 4128: Loss = 48.8491\n",
      "Trajectory ID 5146: Loss = 48.7700\n",
      "Trajectory ID 345: Loss = 48.7313\n",
      "Trajectory ID 5101: Loss = 48.6859\n",
      "Trajectory ID 950: Loss = 48.6097\n",
      "Trajectory ID 2040: Loss = 48.5728\n",
      "Trajectory ID 1021: Loss = 48.5724\n",
      "Trajectory ID 5167: Loss = 48.5439\n",
      "Trajectory ID 1799: Loss = 48.5377\n",
      "Trajectory ID 5097: Loss = 48.5298\n",
      "Trajectory ID 5106: Loss = 48.5214\n",
      "Trajectory ID 3641: Loss = 48.5119\n",
      "Trajectory ID 1025: Loss = 48.4928\n",
      "Trajectory ID 5117: Loss = 48.4448\n",
      "Trajectory ID 4482: Loss = 48.4114\n",
      "Trajectory ID 1044: Loss = 48.4029\n",
      "Trajectory ID 5187: Loss = 48.3884\n",
      "Trajectory ID 1023: Loss = 48.3811\n",
      "Trajectory ID 2342: Loss = 48.2866\n",
      "Trajectory ID 4175: Loss = 48.2805\n",
      "Trajectory ID 52: Loss = 48.2262\n",
      "Trajectory ID 474: Loss = 48.1991\n",
      "Trajectory ID 1548: Loss = 48.1968\n",
      "Trajectory ID 3535: Loss = 48.0942\n",
      "Trajectory ID 1496: Loss = 48.0503\n",
      "Trajectory ID 4068: Loss = 48.0280\n",
      "Trajectory ID 5139: Loss = 47.9734\n",
      "Trajectory ID 1376: Loss = 47.9559\n",
      "Trajectory ID 3207: Loss = 47.9417\n",
      "Trajectory ID 4219: Loss = 47.9307\n",
      "Trajectory ID 5166: Loss = 47.9167\n",
      "Trajectory ID 4353: Loss = 47.9014\n",
      "Trajectory ID 3201: Loss = 47.8367\n",
      "Trajectory ID 2285: Loss = 47.7963\n",
      "Trajectory ID 772: Loss = 47.7892\n",
      "Trajectory ID 2989: Loss = 47.7831\n",
      "Trajectory ID 5121: Loss = 47.7752\n",
      "Trajectory ID 3005: Loss = 47.7673\n",
      "Trajectory ID 3282: Loss = 47.7546\n",
      "Trajectory ID 1089: Loss = 47.5876\n",
      "Trajectory ID 1797: Loss = 47.5828\n",
      "Trajectory ID 444: Loss = 47.5683\n",
      "Trajectory ID 2678: Loss = 47.5533\n",
      "Trajectory ID 113: Loss = 47.5273\n",
      "Trajectory ID 4960: Loss = 47.5263\n",
      "Trajectory ID 2918: Loss = 47.4281\n",
      "Trajectory ID 1773: Loss = 47.3079\n",
      "Trajectory ID 1782: Loss = 47.2896\n",
      "Trajectory ID 5144: Loss = 47.2866\n",
      "Trajectory ID 1351: Loss = 47.2423\n",
      "Trajectory ID 936: Loss = 47.2203\n",
      "Trajectory ID 5193: Loss = 47.1556\n",
      "Trajectory ID 1054: Loss = 47.1474\n",
      "Trajectory ID 5148: Loss = 47.1136\n",
      "Trajectory ID 5114: Loss = 47.0899\n",
      "Trajectory ID 5164: Loss = 47.0760\n",
      "Trajectory ID 2098: Loss = 47.0383\n",
      "Trajectory ID 5176: Loss = 47.0072\n",
      "Trajectory ID 5134: Loss = 46.9933\n",
      "Trajectory ID 1085: Loss = 46.9842\n",
      "Trajectory ID 1015: Loss = 46.9831\n",
      "Trajectory ID 1064: Loss = 46.9697\n",
      "Trajectory ID 2651: Loss = 46.9509\n",
      "Trajectory ID 5102: Loss = 46.8348\n",
      "Trajectory ID 4129: Loss = 46.7798\n",
      "Trajectory ID 4188: Loss = 46.7303\n",
      "Trajectory ID 4715: Loss = 46.6903\n",
      "Trajectory ID 1002: Loss = 46.6539\n",
      "Trajectory ID 5180: Loss = 46.6390\n",
      "Trajectory ID 5174: Loss = 46.6280\n",
      "Trajectory ID 5110: Loss = 46.5952\n",
      "Trajectory ID 1029: Loss = 46.5876\n",
      "Trajectory ID 1220: Loss = 46.5581\n",
      "Trajectory ID 5129: Loss = 46.4496\n",
      "Trajectory ID 4708: Loss = 46.4366\n",
      "Trajectory ID 5163: Loss = 46.4115\n",
      "Trajectory ID 5143: Loss = 46.3843\n",
      "Trajectory ID 1145: Loss = 46.3833\n",
      "Trajectory ID 5104: Loss = 46.3376\n",
      "Trajectory ID 5132: Loss = 46.3089\n",
      "Trajectory ID 2950: Loss = 46.2836\n",
      "Trajectory ID 1594: Loss = 46.2606\n",
      "Trajectory ID 1243: Loss = 46.2471\n",
      "Trajectory ID 3370: Loss = 46.2470\n",
      "Trajectory ID 2999: Loss = 46.2393\n",
      "Trajectory ID 1155: Loss = 46.1312\n",
      "Trajectory ID 2468: Loss = 46.1304\n",
      "Trajectory ID 417: Loss = 46.1265\n",
      "Trajectory ID 401: Loss = 46.1057\n",
      "Trajectory ID 2735: Loss = 46.0703\n",
      "Trajectory ID 1050: Loss = 46.0196\n",
      "Trajectory ID 4021: Loss = 45.9772\n",
      "Trajectory ID 5109: Loss = 45.9162\n",
      "Trajectory ID 3572: Loss = 45.8998\n",
      "Trajectory ID 912: Loss = 45.8614\n",
      "Trajectory ID 3812: Loss = 45.8019\n",
      "Trajectory ID 4711: Loss = 45.7544\n",
      "Trajectory ID 4178: Loss = 45.6978\n",
      "Trajectory ID 4056: Loss = 45.6698\n",
      "Trajectory ID 1034: Loss = 45.5839\n",
      "Trajectory ID 1084: Loss = 45.5743\n",
      "Trajectory ID 4150: Loss = 45.5624\n",
      "Trajectory ID 5119: Loss = 45.5118\n",
      "Trajectory ID 3824: Loss = 45.5080\n",
      "Trajectory ID 1171: Loss = 45.4874\n",
      "Trajectory ID 3733: Loss = 45.4812\n",
      "Trajectory ID 3516: Loss = 45.4689\n",
      "Trajectory ID 3258: Loss = 45.4351\n",
      "Trajectory ID 58: Loss = 45.3945\n",
      "Trajectory ID 3025: Loss = 45.3695\n",
      "Trajectory ID 5094: Loss = 45.3580\n",
      "Trajectory ID 2783: Loss = 45.3479\n",
      "Trajectory ID 3308: Loss = 45.3364\n",
      "Trajectory ID 3898: Loss = 45.2972\n",
      "Trajectory ID 178: Loss = 45.2916\n",
      "Trajectory ID 3231: Loss = 45.2660\n",
      "Trajectory ID 2887: Loss = 45.2617\n",
      "Trajectory ID 4113: Loss = 45.2478\n",
      "Trajectory ID 534: Loss = 45.2322\n",
      "Trajectory ID 4600: Loss = 45.1978\n",
      "Trajectory ID 5177: Loss = 45.1535\n",
      "Trajectory ID 4015: Loss = 45.1233\n",
      "Trajectory ID 7: Loss = 45.1107\n",
      "Trajectory ID 1109: Loss = 45.0714\n",
      "Trajectory ID 5173: Loss = 45.0431\n",
      "Trajectory ID 405: Loss = 45.0125\n",
      "Trajectory ID 1609: Loss = 44.9933\n",
      "Trajectory ID 4281: Loss = 44.9683\n",
      "Trajectory ID 1729: Loss = 44.9392\n",
      "Trajectory ID 1415: Loss = 44.8419\n",
      "Trajectory ID 5169: Loss = 44.7985\n",
      "Trajectory ID 4908: Loss = 44.7837\n",
      "Trajectory ID 1061: Loss = 44.7776\n",
      "Trajectory ID 2202: Loss = 44.7529\n",
      "Trajectory ID 5154: Loss = 44.6484\n",
      "Trajectory ID 4647: Loss = 44.6207\n",
      "Trajectory ID 1926: Loss = 44.5868\n",
      "Trajectory ID 5162: Loss = 44.5449\n",
      "Trajectory ID 15: Loss = 44.5052\n",
      "Trajectory ID 565: Loss = 44.4639\n",
      "Trajectory ID 2578: Loss = 44.4182\n",
      "Trajectory ID 462: Loss = 44.3870\n",
      "Trajectory ID 2055: Loss = 44.2884\n",
      "Trajectory ID 1: Loss = 44.2676\n",
      "Trajectory ID 5098: Loss = 44.2458\n",
      "Trajectory ID 3531: Loss = 44.2301\n",
      "Trajectory ID 1000: Loss = 44.2143\n",
      "Trajectory ID 5122: Loss = 44.2046\n",
      "Trajectory ID 1036: Loss = 44.1900\n",
      "Trajectory ID 2349: Loss = 44.1185\n",
      "Trajectory ID 220: Loss = 44.0934\n",
      "Trajectory ID 1048: Loss = 44.0917\n",
      "Trajectory ID 4078: Loss = 44.0776\n",
      "Trajectory ID 1275: Loss = 44.0676\n",
      "Trajectory ID 1440: Loss = 44.0524\n",
      "Trajectory ID 1405: Loss = 44.0337\n",
      "Trajectory ID 2154: Loss = 44.0323\n",
      "Trajectory ID 1312: Loss = 44.0133\n",
      "Trajectory ID 4721: Loss = 43.9647\n",
      "Trajectory ID 284: Loss = 43.9476\n",
      "Trajectory ID 5160: Loss = 43.9201\n",
      "Trajectory ID 1004: Loss = 43.8951\n",
      "Trajectory ID 5165: Loss = 43.8800\n",
      "Trajectory ID 3864: Loss = 43.8749\n",
      "Trajectory ID 4227: Loss = 43.8543\n",
      "Trajectory ID 244: Loss = 43.8462\n",
      "Trajectory ID 4319: Loss = 43.8452\n",
      "Trajectory ID 2283: Loss = 43.8198\n",
      "Trajectory ID 1195: Loss = 43.7663\n",
      "Trajectory ID 2431: Loss = 43.7621\n",
      "Trajectory ID 460: Loss = 43.6741\n",
      "Trajectory ID 4848: Loss = 43.6684\n",
      "Trajectory ID 2726: Loss = 43.5886\n",
      "Trajectory ID 14: Loss = 43.5675\n",
      "Trajectory ID 2509: Loss = 43.5621\n",
      "Trajectory ID 2014: Loss = 43.4592\n",
      "Trajectory ID 4081: Loss = 43.4339\n",
      "Trajectory ID 1462: Loss = 43.4114\n",
      "Trajectory ID 2198: Loss = 43.3861\n",
      "Trajectory ID 3624: Loss = 43.3805\n",
      "Trajectory ID 321: Loss = 43.3728\n",
      "Trajectory ID 2144: Loss = 43.3043\n",
      "Trajectory ID 3009: Loss = 43.2750\n",
      "Trajectory ID 945: Loss = 43.2436\n",
      "Trajectory ID 2873: Loss = 43.2272\n",
      "Trajectory ID 5082: Loss = 43.1966\n",
      "Trajectory ID 3105: Loss = 43.1892\n",
      "Trajectory ID 2163: Loss = 43.1891\n",
      "Trajectory ID 3966: Loss = 43.1482\n",
      "Trajectory ID 1298: Loss = 43.1266\n",
      "Trajectory ID 3389: Loss = 43.1161\n",
      "Trajectory ID 3708: Loss = 43.0671\n",
      "Trajectory ID 4086: Loss = 43.0547\n",
      "Trajectory ID 1439: Loss = 42.9763\n",
      "Trajectory ID 69: Loss = 42.8959\n",
      "Trajectory ID 3999: Loss = 42.8776\n",
      "Trajectory ID 3272: Loss = 42.8483\n",
      "Trajectory ID 2361: Loss = 42.7886\n",
      "Trajectory ID 1383: Loss = 42.7840\n",
      "Trajectory ID 4665: Loss = 42.7579\n",
      "Trajectory ID 1174: Loss = 42.6979\n",
      "Trajectory ID 1039: Loss = 42.6843\n",
      "Trajectory ID 1851: Loss = 42.6733\n",
      "Trajectory ID 4529: Loss = 42.6732\n",
      "Trajectory ID 2186: Loss = 42.6568\n",
      "Trajectory ID 4856: Loss = 42.5705\n",
      "Trajectory ID 5172: Loss = 42.5642\n",
      "Trajectory ID 2452: Loss = 42.4905\n",
      "Trajectory ID 1665: Loss = 42.4774\n",
      "Trajectory ID 706: Loss = 42.4612\n",
      "Trajectory ID 609: Loss = 42.4512\n",
      "Trajectory ID 1574: Loss = 42.4432\n",
      "Trajectory ID 27: Loss = 42.4075\n",
      "Trajectory ID 3288: Loss = 42.3945\n",
      "Trajectory ID 5185: Loss = 42.3756\n",
      "Trajectory ID 5151: Loss = 42.3481\n",
      "Trajectory ID 5128: Loss = 42.3396\n",
      "Trajectory ID 1946: Loss = 42.3341\n",
      "Trajectory ID 1066: Loss = 42.2814\n",
      "Trajectory ID 1045: Loss = 42.2471\n",
      "Trajectory ID 2810: Loss = 42.2137\n",
      "Trajectory ID 2593: Loss = 42.1967\n",
      "Trajectory ID 4107: Loss = 42.1852\n",
      "Trajectory ID 334: Loss = 42.1619\n",
      "Trajectory ID 2730: Loss = 42.1593\n",
      "Trajectory ID 1057: Loss = 42.1510\n",
      "Trajectory ID 215: Loss = 42.1473\n",
      "Trajectory ID 4253: Loss = 42.1401\n",
      "Trajectory ID 4568: Loss = 42.0675\n",
      "Trajectory ID 3584: Loss = 42.0240\n",
      "Trajectory ID 2222: Loss = 42.0114\n",
      "Trajectory ID 3639: Loss = 41.9933\n",
      "Trajectory ID 4275: Loss = 41.9449\n",
      "Trajectory ID 3976: Loss = 41.8080\n",
      "Trajectory ID 1040: Loss = 41.8066\n",
      "Trajectory ID 3735: Loss = 41.7597\n",
      "Trajectory ID 3996: Loss = 41.7426\n",
      "Trajectory ID 2224: Loss = 41.7108\n",
      "Trajectory ID 4744: Loss = 41.6627\n",
      "Trajectory ID 1577: Loss = 41.5907\n",
      "Trajectory ID 3962: Loss = 41.5803\n",
      "Trajectory ID 2558: Loss = 41.5727\n",
      "Trajectory ID 1037: Loss = 41.5531\n",
      "Trajectory ID 514: Loss = 41.5508\n",
      "Trajectory ID 2956: Loss = 41.5185\n",
      "Trajectory ID 4233: Loss = 41.4923\n",
      "Trajectory ID 4877: Loss = 41.4875\n",
      "Trajectory ID 4154: Loss = 41.4096\n",
      "Trajectory ID 78: Loss = 41.3963\n",
      "Trajectory ID 5190: Loss = 41.3671\n",
      "Trajectory ID 251: Loss = 41.3035\n",
      "Trajectory ID 1257: Loss = 41.2823\n",
      "Trajectory ID 1311: Loss = 41.2713\n",
      "Trajectory ID 4992: Loss = 41.2559\n",
      "Trajectory ID 84: Loss = 41.2388\n",
      "Trajectory ID 3904: Loss = 41.1999\n",
      "Trajectory ID 3961: Loss = 41.1890\n",
      "Trajectory ID 578: Loss = 41.1872\n",
      "Trajectory ID 68: Loss = 41.1711\n",
      "Trajectory ID 4797: Loss = 41.1143\n",
      "Trajectory ID 2263: Loss = 41.0992\n",
      "Trajectory ID 4639: Loss = 41.0921\n",
      "Trajectory ID 593: Loss = 41.0325\n",
      "Trajectory ID 872: Loss = 41.0233\n",
      "Trajectory ID 5116: Loss = 40.9795\n",
      "Trajectory ID 4940: Loss = 40.9309\n",
      "Trajectory ID 218: Loss = 40.9224\n",
      "Trajectory ID 539: Loss = 40.9189\n",
      "Trajectory ID 1181: Loss = 40.8873\n",
      "Trajectory ID 4028: Loss = 40.8516\n",
      "Trajectory ID 2901: Loss = 40.8305\n",
      "Trajectory ID 1571: Loss = 40.8281\n",
      "Trajectory ID 2191: Loss = 40.7931\n",
      "Trajectory ID 3117: Loss = 40.7188\n",
      "Trajectory ID 1988: Loss = 40.7163\n",
      "Trajectory ID 450: Loss = 40.7111\n",
      "Trajectory ID 2859: Loss = 40.6972\n",
      "Trajectory ID 4414: Loss = 40.6586\n",
      "Trajectory ID 1954: Loss = 40.6415\n",
      "Trajectory ID 4497: Loss = 40.6309\n",
      "Trajectory ID 1253: Loss = 40.5866\n",
      "Trajectory ID 1201: Loss = 40.5566\n",
      "Trajectory ID 3545: Loss = 40.5386\n",
      "Trajectory ID 3182: Loss = 40.5226\n",
      "Trajectory ID 4543: Loss = 40.4669\n",
      "Trajectory ID 3589: Loss = 40.4641\n",
      "Trajectory ID 4122: Loss = 40.4180\n",
      "Trajectory ID 427: Loss = 40.4140\n",
      "Trajectory ID 1329: Loss = 40.4096\n",
      "Trajectory ID 1746: Loss = 40.3822\n",
      "Trajectory ID 3153: Loss = 40.3817\n",
      "Trajectory ID 1238: Loss = 40.3567\n",
      "Trajectory ID 1178: Loss = 40.3453\n",
      "Trajectory ID 1105: Loss = 40.3207\n",
      "Trajectory ID 2852: Loss = 40.2994\n",
      "Trajectory ID 3701: Loss = 40.2673\n",
      "Trajectory ID 4605: Loss = 40.2073\n",
      "Trajectory ID 1098: Loss = 40.1540\n",
      "Trajectory ID 3759: Loss = 40.1426\n",
      "Trajectory ID 2295: Loss = 40.1010\n",
      "Trajectory ID 1720: Loss = 40.0822\n",
      "Trajectory ID 3508: Loss = 40.0754\n",
      "Trajectory ID 1493: Loss = 40.0564\n",
      "Trajectory ID 3828: Loss = 40.0384\n",
      "Trajectory ID 1487: Loss = 40.0077\n",
      "Trajectory ID 1401: Loss = 39.9953\n",
      "Trajectory ID 1150: Loss = 39.9906\n",
      "Trajectory ID 274: Loss = 39.9759\n",
      "Trajectory ID 5105: Loss = 39.9719\n",
      "Trajectory ID 3673: Loss = 39.9493\n",
      "Trajectory ID 4580: Loss = 39.8705\n",
      "Trajectory ID 4634: Loss = 39.8443\n",
      "Trajectory ID 1997: Loss = 39.8164\n",
      "Trajectory ID 4020: Loss = 39.7989\n",
      "Trajectory ID 5090: Loss = 39.7632\n",
      "Trajectory ID 1591: Loss = 39.7313\n",
      "Trajectory ID 396: Loss = 39.7186\n",
      "Trajectory ID 1343: Loss = 39.6942\n",
      "Trajectory ID 1235: Loss = 39.6773\n",
      "Trajectory ID 3004: Loss = 39.6628\n",
      "Trajectory ID 2650: Loss = 39.5832\n",
      "Trajectory ID 3839: Loss = 39.5549\n",
      "Trajectory ID 346: Loss = 39.4770\n",
      "Trajectory ID 5111: Loss = 39.4337\n",
      "Trajectory ID 4330: Loss = 39.3720\n",
      "Trajectory ID 4376: Loss = 39.3001\n",
      "Trajectory ID 409: Loss = 39.2375\n",
      "Trajectory ID 2386: Loss = 39.1808\n",
      "Trajectory ID 2022: Loss = 39.1634\n",
      "Trajectory ID 3317: Loss = 39.0242\n",
      "Trajectory ID 946: Loss = 39.0173\n",
      "Trajectory ID 4812: Loss = 38.9879\n",
      "Trajectory ID 138: Loss = 38.9218\n",
      "Trajectory ID 3410: Loss = 38.8991\n",
      "Trajectory ID 2146: Loss = 38.8821\n",
      "Trajectory ID 1247: Loss = 38.8540\n",
      "Trajectory ID 382: Loss = 38.8217\n",
      "Trajectory ID 1340: Loss = 38.7668\n",
      "\n",
      "Detected 84 truly abnormal trajectories in top 100:\n",
      "Trajectory ID 1022: Loss = 61.1130\n",
      "Trajectory ID 1017: Loss = 60.2809\n",
      "Trajectory ID 1056: Loss = 59.8945\n",
      "Trajectory ID 5108: Loss = 59.4831\n",
      "Trajectory ID 5103: Loss = 59.4693\n",
      "Trajectory ID 5142: Loss = 59.3265\n",
      "Trajectory ID 1058: Loss = 58.8943\n",
      "Trajectory ID 1093: Loss = 58.7785\n",
      "Trajectory ID 1010: Loss = 58.2182\n",
      "Trajectory ID 5133: Loss = 58.0130\n",
      "Trajectory ID 1062: Loss = 58.0024\n",
      "Trajectory ID 5179: Loss = 57.9569\n",
      "Trajectory ID 1019: Loss = 57.7927\n",
      "Trajectory ID 1031: Loss = 57.7583\n",
      "Trajectory ID 1081: Loss = 57.6966\n",
      "Trajectory ID 1024: Loss = 57.3848\n",
      "Trajectory ID 1097: Loss = 57.3369\n",
      "Trajectory ID 5181: Loss = 56.7913\n",
      "Trajectory ID 1046: Loss = 56.6227\n",
      "Trajectory ID 5127: Loss = 56.3987\n",
      "Trajectory ID 1086: Loss = 56.3360\n",
      "Trajectory ID 1014: Loss = 56.3124\n",
      "Trajectory ID 1088: Loss = 56.3079\n",
      "Trajectory ID 1011: Loss = 56.2068\n",
      "Trajectory ID 5197: Loss = 56.1398\n",
      "Trajectory ID 1006: Loss = 56.1246\n",
      "Trajectory ID 1063: Loss = 56.0196\n",
      "Trajectory ID 5136: Loss = 56.0154\n",
      "Trajectory ID 1026: Loss = 55.9945\n",
      "Trajectory ID 5192: Loss = 55.9939\n",
      "Trajectory ID 1068: Loss = 55.9246\n",
      "Trajectory ID 1076: Loss = 55.8296\n",
      "Trajectory ID 5156: Loss = 55.7988\n",
      "Trajectory ID 1099: Loss = 55.5948\n",
      "Trajectory ID 5155: Loss = 55.4883\n",
      "Trajectory ID 1008: Loss = 55.3810\n",
      "Trajectory ID 5175: Loss = 55.3384\n",
      "Trajectory ID 1005: Loss = 55.3074\n",
      "Trajectory ID 5152: Loss = 55.1864\n",
      "Trajectory ID 1038: Loss = 55.1029\n",
      "Trajectory ID 1087: Loss = 55.0222\n",
      "Trajectory ID 1082: Loss = 54.9966\n",
      "Trajectory ID 5153: Loss = 54.9637\n",
      "Trajectory ID 5120: Loss = 54.9102\n",
      "Trajectory ID 1052: Loss = 54.7318\n",
      "Trajectory ID 5123: Loss = 54.6622\n",
      "Trajectory ID 5161: Loss = 54.6397\n",
      "Trajectory ID 5100: Loss = 54.4113\n",
      "Trajectory ID 5137: Loss = 54.3754\n",
      "Trajectory ID 1091: Loss = 54.2969\n",
      "Trajectory ID 5126: Loss = 54.1450\n",
      "Trajectory ID 5149: Loss = 54.0288\n",
      "Trajectory ID 1078: Loss = 54.0222\n",
      "Trajectory ID 5150: Loss = 53.9031\n",
      "Trajectory ID 5183: Loss = 53.8082\n",
      "Trajectory ID 5182: Loss = 53.7948\n",
      "Trajectory ID 1070: Loss = 53.5886\n",
      "Trajectory ID 5194: Loss = 53.5812\n",
      "Trajectory ID 5118: Loss = 53.5191\n",
      "Trajectory ID 1020: Loss = 53.3693\n",
      "Trajectory ID 5189: Loss = 53.3622\n",
      "Trajectory ID 5115: Loss = 53.2750\n",
      "Trajectory ID 5158: Loss = 53.2385\n",
      "Trajectory ID 5186: Loss = 53.1046\n",
      "Trajectory ID 1016: Loss = 53.0776\n",
      "Trajectory ID 5147: Loss = 53.0372\n",
      "Trajectory ID 5178: Loss = 52.7247\n",
      "Trajectory ID 5196: Loss = 52.6036\n",
      "Trajectory ID 5198: Loss = 52.3994\n",
      "Trajectory ID 1041: Loss = 52.2874\n",
      "Trajectory ID 1069: Loss = 52.2686\n",
      "Trajectory ID 5130: Loss = 52.2386\n",
      "Trajectory ID 5107: Loss = 52.1228\n",
      "Trajectory ID 5112: Loss = 52.1123\n",
      "Trajectory ID 5113: Loss = 51.8329\n",
      "Trajectory ID 1072: Loss = 51.8002\n",
      "Trajectory ID 1030: Loss = 51.7164\n",
      "Trajectory ID 5140: Loss = 51.6204\n",
      "Trajectory ID 1074: Loss = 51.5867\n",
      "Trajectory ID 1043: Loss = 51.4596\n",
      "Trajectory ID 1009: Loss = 51.3724\n",
      "Trajectory ID 5145: Loss = 51.1744\n",
      "Trajectory ID 1018: Loss = 51.1222\n",
      "Trajectory ID 1059: Loss = 51.0433\n",
      "\n",
      "Precision@100 = 0.84\n"
     ]
    }
   ],
   "source": [
    "def evaluate_precision_at_k(sorted_pairs, top_k=50, abnormal_ranges=None):\n",
    "    \"\"\"\n",
    "    Calculates precision@k for detecting abnormal trajectories.\n",
    "\n",
    "    Args:\n",
    "        sorted_pairs (list of tuples): (trajectory_id, loss) pairs sorted by loss descending.\n",
    "        top_k (int): Number of top trajectories to consider.\n",
    "        abnormal_ranges (list of ints): List of trajectory IDs considered abnormal.\n",
    "\n",
    "    Returns:\n",
    "        abnormal_detected (list of tuples): Abnormal (ID, loss) found in top_k.\n",
    "        precision (float): Precision@k value.\n",
    "    \"\"\"\n",
    "    if abnormal_ranges is None:\n",
    "        abnormal_ranges = list(range(1000, 1100)) + list(range(5100, 5200))\n",
    "\n",
    "    top_k_subset = sorted_pairs[:top_k]\n",
    "    abnormal_detected = [(traj_id, loss) for traj_id, loss in top_k_subset if traj_id in abnormal_ranges]\n",
    "\n",
    "    print(f\"\\nDetected {len(abnormal_detected)} truly abnormal trajectories in top {top_k}:\")\n",
    "    for traj_id, loss in abnormal_detected:\n",
    "        print(f\"Trajectory ID {traj_id}: Loss = {loss:.4f}\")\n",
    "\n",
    "    precision = len(abnormal_detected) / top_k\n",
    "    print(f\"\\nPrecision@{top_k} = {precision:.2f}\")\n",
    "\n",
    "    return abnormal_detected, precision\n",
    "\n",
    "sorted_pairs = evaluate_anomalies(model, test_loader, device, test_indices=test_indices, top_k=500)\n",
    "\n",
    "abnormal_detected, precision = evaluate_precision_at_k(sorted_pairs, top_k=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8ba5705-ef69-4656-9a32-7f04185810b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Trajectory ID: 1022\n",
      "Data (x): tensor([[[ 1.1615,  0.6840,  0.1611,  ...,  0.4761,  0.5734, -1.2865],\n",
      "         [ 0.0233, -0.4054, -0.8051,  ...,  0.4761,  0.5734, -1.2865],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0233, -0.4054, -0.8051,  ..., -0.0146, -0.4107,  1.2548],\n",
      "         [ 1.1615,  0.6840,  0.1611,  ..., -0.0146, -0.4107,  1.2548],\n",
      "         [ 0.9777, -0.7392, -0.4093,  ..., -0.0146, -0.4107,  1.2548],\n",
      "         [-0.3114, -2.3895,  0.1585,  ..., -0.0146, -0.4107,  1.2548]],\n",
      "\n",
      "        [[ 0.0233, -0.4054, -0.8051,  ...,  0.0656, -0.5021,  0.8280],\n",
      "         [ 0.9777, -0.7392, -0.4093,  ...,  0.0656, -0.5021,  0.8280],\n",
      "         [ 1.1615,  0.6840,  0.1611,  ...,  0.0656, -0.5021,  0.8280],\n",
      "         [-0.3114, -2.3895,  0.1585,  ...,  0.0656, -0.5021,  0.8280]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# Get top trajectory ID (with highest loss)\n",
    "top_traj_id = sorted_pairs[0][0]\n",
    "\n",
    "# Retrieve from the original dataset\n",
    "top_data = dataset[top_traj_id]\n",
    "top_x, top_action_mask, top_timestep_mask = top_data\n",
    "\n",
    "# Print nicely\n",
    "print(f\"\\nTop Trajectory ID: {top_traj_id}\")\n",
    "print(\"Data (x):\", top_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77deada7-cee0-4ca6-989c-c1838fba8165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
