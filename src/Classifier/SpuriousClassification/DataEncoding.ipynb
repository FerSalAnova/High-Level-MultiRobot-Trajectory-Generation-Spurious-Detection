{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f538074-9d73-4dda-abb6-3b364a8f708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d04b2-ec14-4057-af5a-7f66e90ade1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trajectories(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    blocks = content.strip().split(\"\\n\\n\")  # Split by blank lines (trajectories)\n",
    "    all_trajectories = []\n",
    "\n",
    "    for block in blocks:\n",
    "        lines = block.strip().split(\"\\n\")\n",
    "        trajectory = []\n",
    "\n",
    "        for line in lines:\n",
    "            actions = line.strip().split(\"-\")\n",
    "            timestep = []\n",
    "\n",
    "            for action in actions:\n",
    "                # Updated regex to support float durations\n",
    "                match = re.match(r\"r(\\d+)\\((\\d+(?:\\.\\d+)?)\\):p(\\d+)\\(([^)]+)\\),p(\\d+)\\(([^)]+)\\)\", action.strip())\n",
    "                if match:\n",
    "                    r_id, duration_str, p_start, y_start_str, p_end, y_end_str = match.groups()\n",
    "\n",
    "                    # Convert duration to float\n",
    "                    duration = float(duration_str)\n",
    "                    y_start = [int(label[1:]) for label in y_start_str.split(',')]\n",
    "                    y_end = [int(label[1:]) for label in y_end_str.split(',')]\n",
    "\n",
    "                    timestep.append({\n",
    "                        \"robot_id\": int(r_id),\n",
    "                        \"duration\": duration,\n",
    "                        \"p_start\": int(p_start),\n",
    "                        \"y_start\": y_start,\n",
    "                        \"p_end\": int(p_end),\n",
    "                        \"y_end\": y_end\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Warning: Could not parse action: {action}\")\n",
    "            trajectory.append(timestep)\n",
    "\n",
    "        all_trajectories.append(trajectory)\n",
    "\n",
    "    return all_trajectories\n",
    "\n",
    "# Parse the data from the log file\n",
    "parsed_data = parse_trajectories(\"your_path.txt\")\n",
    "\n",
    "# Print the parsed data for the first timestep in the first trajectory\n",
    "print(parsed_data[0][0])  # first timestep in that trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0075ff6-c65d-4285-a474-73f29ac61ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_long_trajectories(file_path, max_timesteps=10):\n",
    "    \"\"\"\n",
    "    Reads a .txt file of trajectories and returns a list of indices of those\n",
    "    trajectories that have more than `max_timesteps` timesteps.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the trajectory file.\n",
    "        max_timesteps (int): Threshold for maximum allowed timesteps.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: Indices of long (spurious) trajectories.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    blocks = content.strip().split(\"\\n\\n\")\n",
    "    long_traj_ids = []\n",
    "\n",
    "    for i, block in enumerate(blocks):\n",
    "        lines = block.strip().split(\"\\n\")\n",
    "        if len(lines) > max_timesteps:\n",
    "            long_traj_ids.append(i)\n",
    "\n",
    "    return long_traj_ids\n",
    "\n",
    "file_path = \"your_path.txt\"\n",
    "long_ids_dataset = find_long_trajectories(file_path, max_timesteps)\n",
    "print(\"Dataset too long trajectories: \", len(long_ids_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31de2ab-e47f-4f4b-be87-b0ca393c15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max ids from the parsed data\n",
    "robot_ids = set()\n",
    "place_ids = set()\n",
    "\n",
    "for traj in parsed_data:\n",
    "    for timestep in traj:\n",
    "        for action in timestep:\n",
    "            robot_ids.add(action['robot_id'])\n",
    "            place_ids.add(action['p_start'])\n",
    "            place_ids.add(action['p_end'])\n",
    "\n",
    "max_robot_id = max(robot_ids) + 1\n",
    "max_place_id = max(place_ids) + 1\n",
    "max_timesteps = max(len(traj) for traj in parsed_data)\n",
    "\n",
    "# Then initialize your embeddings\n",
    "embed_dim = 32\n",
    "robot_embedding_matrix = nn.Embedding(max_robot_id, embed_dim)\n",
    "place_embedding_matrix = nn.Embedding(max_place_id, embed_dim)\n",
    "timestep_embedding_matrix = nn.Embedding(max_timesteps, embed_dim)\n",
    "\n",
    "# If you want to just use tensors here, extract their weight data:\n",
    "robot_embeddings = robot_embedding_matrix.weight.data  # shape (max_robot_id, embed_dim)\n",
    "place_embeddings = place_embedding_matrix.weight.data  # shape (max_place_id, embed_dim)\n",
    "\n",
    "def sinusoidal_embedding(value, dim=32):\n",
    "    \"\"\"Sinusoidal embedding for a scalar value.\"\"\"\n",
    "    pe = torch.zeros(dim)\n",
    "    position = torch.tensor(value, dtype=torch.float32)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(np.log(10000.0) / dim))\n",
    "    pe[0::2] = torch.sin(position * div_term)\n",
    "    pe[1::2] = torch.cos(position * div_term)\n",
    "    return pe\n",
    "\n",
    "def time_embedding(duration, max_duration):\n",
    "    \"\"\"Sinusoidal encoding for duration using 2D angle.\"\"\"\n",
    "    normalized = np.log(duration + 1) / np.log(max_duration + 1)\n",
    "    angle = 2 * np.pi * normalized\n",
    "    return torch.tensor([np.sin(angle), np.cos(angle)], dtype=torch.float32)\n",
    "\n",
    "def label_embedding(y_start, y_end, num_labels=5):\n",
    "    \"\"\"Label transition encoding: -1 for origin labels, 1 for destination labels, 0 otherwise.\"\"\"\n",
    "    vec = torch.zeros(num_labels)\n",
    "    for i in y_start:\n",
    "        vec[i - 1] = -1\n",
    "    for i in y_end:\n",
    "        if vec[i - 1] == -1:\n",
    "            vec[i - 1] = 0  # neutralize if label is both in start and end\n",
    "        else:\n",
    "            vec[i - 1] = 1\n",
    "    return vec\n",
    "\n",
    "def timestep_embedding(position, dim=32):\n",
    "    \"\"\"Sinusoidal positional encoding for timestep index.\"\"\"\n",
    "    pe = torch.zeros(dim)\n",
    "    position = torch.tensor(position, dtype=torch.float32)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(np.log(10000.0) / dim))\n",
    "    pe[0::2] = torch.sin(position * div_term)\n",
    "    pe[1::2] = torch.cos(position * div_term)\n",
    "    return pe\n",
    "\n",
    "#----------------------------------------  MODIFY THE ENCODE ACTIONS FUNCTION AS PLEASED  ---------------------------------------------------------\n",
    "\n",
    "def encode_actions(parsed_data, robot_embeddings, place_embeddings, timestep_embeddings, num_labels=5, embed_dim=32):\n",
    "    max_duration = max(\n",
    "        action['duration']\n",
    "        for trajectory in parsed_data\n",
    "        for timestep in trajectory\n",
    "        for action in timestep\n",
    "    )\n",
    "    \n",
    "    encoded_vectors = []\n",
    "\n",
    "    for trajectory in parsed_data:\n",
    "        encoded_trajectory = []\n",
    "\n",
    "        for t_idx, timestep in enumerate(trajectory):\n",
    "            timestep_vec = timestep_embeddings[t_idx]\n",
    "\n",
    "            encoded_timestep = []\n",
    "\n",
    "            for action in timestep:\n",
    "                # Instead of sinusoidal, do lookup here:\n",
    "                robot_vec = robot_embeddings[action['robot_id']]  \n",
    "                p_start_vec = place_embeddings[action['p_start']]\n",
    "                p_end_vec = place_embeddings[action['p_end']]\n",
    "\n",
    "                label_vec = label_embedding(action['y_start'], action['y_end'], num_labels=num_labels)\n",
    "                time_vec = time_embedding(action['duration'], max_duration)\n",
    "\n",
    "                full_vec = torch.cat([\n",
    "                    robot_vec,\n",
    "                    p_start_vec,\n",
    "                    p_end_vec,\n",
    "                    label_vec,\n",
    "                    time_vec,\n",
    "                    timestep_vec\n",
    "                ])\n",
    "\n",
    "                encoded_timestep.append(full_vec)\n",
    "            encoded_trajectory.append(encoded_timestep)\n",
    "\n",
    "        encoded_vectors.append(encoded_trajectory)\n",
    "\n",
    "    return encoded_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10807e25-f35c-44c9-80c6-d5e35b641a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data from the log file\n",
    "data = parse_trajectories(\"your_path.txt\")\n",
    "test = parse_trajectories(\"your_path.txt\")\n",
    "\n",
    "# Set the number of labels manually\n",
    "num_labels = 10  # Change this based on the number of labels you want\n",
    "\n",
    "# Example: create embedding matrices (trainable parameters should be managed separately during training)\n",
    "robot_embedding_matrix = nn.Embedding(max_robot_id, embed_dim)\n",
    "place_embedding_matrix = nn.Embedding(max_place_id, embed_dim)\n",
    "\n",
    "# Pass the weight tensors:\n",
    "data_trajectories = encode_actions(\n",
    "    data,\n",
    "    robot_embedding_matrix.weight.data,\n",
    "    place_embedding_matrix.weight.data,\n",
    "    timestep_embeddings=timestep_embedding_matrix.weight.data,\n",
    "    num_labels=num_labels,\n",
    "    embed_dim=embed_dim\n",
    ")\n",
    "\n",
    "test_trajectories = encode_actions(\n",
    "    test,\n",
    "    robot_embedding_matrix.weight.data,\n",
    "    place_embedding_matrix.weight.data,\n",
    "    timestep_embeddings=timestep_embedding_matrix.weight.data,\n",
    "    num_labels=num_labels,\n",
    "    embed_dim=embed_dim\n",
    ")\n",
    "\n",
    "# Print the encoded vector for the first timestep in the first trajectory\n",
    "print(data_trajectories[0][0][0])  # First timestep in the first trajectory\n",
    "print(f\"Vector size: {test_trajectories[0][0][0].shape}\")  # Expected size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d1fda-6aa3-4612-ab3c-a364bc7939af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_trajectories_flat(encoded_vectors):\n",
    "    \"\"\"\n",
    "    Convert each trajectory into a flat sequence of action vectors.\n",
    "    Returns a list of tensors: each tensor is (num_actions, 137)\n",
    "    \"\"\"\n",
    "    flat_trajectories = []\n",
    "\n",
    "    for traj in encoded_vectors:\n",
    "        actions = []\n",
    "        for timestep in traj:\n",
    "            actions.extend(timestep)  # Flatten timestep\n",
    "        traj_tensor = torch.stack(actions)  # Shape: (num_actions, 137)\n",
    "        flat_trajectories.append(traj_tensor)\n",
    "\n",
    "    return flat_trajectories\n",
    "\n",
    "data_vector = organize_trajectories_flat(data_trajectories)\n",
    "test_vector = organize_trajectories_flat(test_trajetories)\n",
    "# Inspect\n",
    "print(flat_trajectories[0].shape)  # Should be (num_actions_in_first_traj, feature_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
